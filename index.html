<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EdgeSR: Image Super-Resolution Using Edge-Guided Diffusion Models">
  <meta name="keywords" content="EdgeSR">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EdgeSR: Image Super-Resolution Using Edge-Guided Diffusion Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .inline-equation {
      display: inline-block;
      vertical-align: middle;
    }
  </style>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <!-- FIX THE LINK -->
                <a href="https://arxiv.org/abs/2403.14773"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=GDPP0zmFmQg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Picsart-AI-Research/StreamingT2V"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Demo Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="./static/images/hf.png" alt="Button Image">
                  </span>
                  <span>Demo (Coming Soon)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/teaser.png" style="width:100%;height:100%;">
      <p class="subtitle has-text-centered">
        <b><span class="dnerf">EdgeSR</span></b> is a cutting-edge super-resolution technology designed to enhance the clarity and detail of images at the edge level. It is adept at processing a wide range of image types, demonstrating its versatility and effectiveness across different content scenarios. Our tests show significant improvements in image quality, with EdgeSR effectively resolving finer textures and details that are often lost in standard methods. This technology is particularly beneficial for applications requiring high-resolution outputs, such as digital photography, medical imaging, and video enhancement. The robustness of EdgeSR is further exemplified by its ability to maintain high image quality even under challenging conditions, making it a reliable tool for professionals and enthusiasts seeking to enhance their visual media.
    </div>
  </div>
</section>


<section class="section b-section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The advent of diffusion models in image super-resolution (SR) has marked a transformative era in generating high-fidelity, high-resolution images from lower-resolution counterparts.
            However, traditional approaches to diffusion-based SR have grappled with significant challenges, notably noticeable degradation of image quality, producing outputs that lack sharpness and detail.
            Thus, our research presents a novel plug-and-play module for any diffusion-based image super-resolution (SR) method, which improves image details by incorporating an edge detection algorithm into the reverse
            diffusion process.During each denoising step in the reverse diffusion process, we utilize edge map to guide the the image reconstruction towards preserving and accentuating these critical features. This targeted guidance helps in molding the
            sharper and more defined edges that are pivotal for high-quality high-resolution images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->

    <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->


    <!--/ Paper video. -->
  </div>
</section>

<!-- 
<section class="section">
  <div class="container is-max-desktop">
    <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 height="100%">
      <source src="./static/videos/StreamingT2V.mp4"
              type="video/mp4">
    </video>
  </div>
</section>
 -->

<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/method.png" style="width:100%;height:80%;">
          <p>
            Method overview: In the <span class="dnerf">Initialization Stage</span>, the first 16-frame chunk is synthesized by a text-to-video model. In the <span class="dnerf">Streaming T2V Stage</span>, the new content for further frames are autoregressively generated. Finally, in the <span class="dnerf">Streaming Refinement Stage</span> the generated long video (600, 1200 frames or more) is autoregressively enhanced by applying a high-resolution text-to-short-video model, equipped with our randomized blending approach.
          </p>
        </div>
      </div>
    </section>
  </div>
</section>

<!-- <script>
  function toggleDetails() {
    var content = document.getElementById("detailed-content");
    var triangle = document.getElementById("triangle");
    if (content.style.display === "none") {
      content.style.display = "block";
      triangle.innerHTML = "▲"; // Change triangle icon to point up
    } else {
      content.style.display = "none";
      triangle.innerHTML = "▼"; // Change triangle icon to point down
    }
  }
</script> -->

<!-- <section class="section" id="Method-Detailed">
  <div class="container is-max-desktop content">
    <h2 class="title">Method Detailed</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/t2v-v8.png" style="width:100%;height:80%;">
          <p>
            Method overview: In the Edge-Guided Image Super Resolution (EdgeSR) model, edge guidance is predominantly implemented in the later stages of the diffusion process to maximize clarity and effectiveness. Starting from a chosen midpoint, denoted as step S (0.5T, where T is the total number of diffusion steps), the model focuses on enhancing edge fidelity. At this stage, the latent image representation is transformed into a spatial image format using a VQ-GAN decoder. The resulting decoded image is then processed by the PiDiNet architecture, a network designed specifically for edge detection and enhancement. PiDiNet predicts an edge map, which is compared to the reference edge map derived from the initial low-resolution input. The discrepancy between the predicted and actual edge maps is quantified using a loss function, guiding the subsequent refinement of the image. This loss influences the diffusion process by integrating an anti-gradient adjustment directly into the latent representation, ensuring             the edges in the super-resolved image align more closely with those in the reference map. This adjustment, controlled by a scaling factor α, balances the strength of the edge guidance against the natural progression of image denoising. Through this method, EdgeSR effectively enhances the edge details in the super-resolved image, leveraging targeted modifications to improve image quality at critical stages of the reconstruction process.
          </p>
        </div>
      </div>
    </section>
  </div>
</section> -->


<section class="section " id="Results">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
    <section class="hero method">
    <div class="container is-max-desktop">
    <div class="hero-body">





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p> If you use our work in your research, please cite our publication: </p>
    <pre><code>@article{streamingt2v,
    title={StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text},
    author={Henschel, Roberto and Khachatryan, Levon and Hayrapetyan, Daniil and Poghosyan, Hayk and Tadevosyan, Vahram and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
    journal={arXiv preprint arXiv:2403.14773},
    year={2024}
  }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- FIX THE LINK -->
      <a class="icon-link" href="https://arxiv.org/abs/2403.14773">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled> -->
      <a class="icon-link" href="https://github.com/Picsart-AI-Research/StreamingT2V" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
