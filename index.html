<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EdgeSR: Image Super-Resolution Using Edge-Guided Diffusion Models">
  <meta name="keywords" content="EdgeSR">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EdgeSR: Image Super-Resolution Using Edge-Guided Diffusion Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .inline-equation {
      display: inline-block;
      vertical-align: middle;
    }
  </style>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EdgeSR: <br> Image Super-Resolution Using Edge-Guided Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/dr-ing-roberto-henschel-6aa1ba176">Roberto Henschel</a><sup>1*</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://levon-kh.github.io/">Levon Khachatryan</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/daniil-hayrapetyan-375b05149/">Daniil Hayrapetyan</a><sup>1*</sup>,</span>
            </span><br>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/hayk-poghosyan-793b97198/">Hayk Poghosyan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/vtadevosian">Vahram Tadevosyan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang">Zhangyang Wang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/shant-navasardyan-1302aa149">Shant Navasardyan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.humphreyshi.com">Humphrey Shi</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Picsart AI Resarch (PAIR),</span>
            <span class="author-block"><sup>2</sup>UT Austin</span>
            <span class="author-block"><sup>3</sup>SHI Labs @ Georgia Tech, Oregon & UIUC</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <!-- FIX THE LINK -->
                <a href="https://arxiv.org/abs/2403.14773"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=GDPP0zmFmQg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Picsart-AI-Research/StreamingT2V"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Demo Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="./static/images/hf.png" alt="Button Image">
                  </span>
                  <span>Demo (Coming Soon)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/teaser.png" style="width:100%;height:100%;">
      <p class="subtitle has-text-centered">
        <b><span class="dnerf">StreamingT2V</span></b> is an advanced autoregressive technique that enables the creation of long videos featuring rich motion dynamics without any stagnation. It ensures temporal consistency throughout the video, aligns closely with the descriptive text, and maintains high frame-level image quality. Our demonstrations include successful examples of videos up to <b>1200 frames, spanning 2 minutes</b>, and can be extended for even longer durations. Importantly, the effectiveness of StreamingT2V is not limited by the specific Text2Video model used, indicating that improvements in base models could yield even higher-quality videos.
      </p>
    </div>
  </div>
</section>


<section class="section b-section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The advent of diffusion models in image super-resolution (SR) has marked a transformative era in generating high-fidelity, high-resolution images from lower-resolution counterparts.
            However, traditional approaches to diffusion-based SR have grappled with significant challenges, notably noticeable degradation of image quality, producing outputs that lack sharpness and detail.
            Thus, our research presents a novel plug-and-play module for any diffusion-based image super-resolution (SR) method, which improves image details by incorporating an edge detection algorithm into the reverse
            diffusion process.During each denoising step in the reverse diffusion process, we utilize edge map to guide the the image reconstruction towards preserving and accentuating these critical features. This targeted guidance helps in molding the
            sharper and more defined edges that are pivotal for high-quality high-resolution images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->

    <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->


    <!--/ Paper video. -->
  </div>
</section>

<!-- 
<section class="section">
  <div class="container is-max-desktop">
    <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 height="100%">
      <source src="./static/videos/StreamingT2V.mp4"
              type="video/mp4">
    </video>
  </div>
</section>
 -->

<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/method.png" style="width:100%;height:80%;">
          <p>
            Method overview: In the <span class="dnerf">Initialization Stage</span>, the first 16-frame chunk is synthesized by a text-to-video model. In the <span class="dnerf">Streaming T2V Stage</span>, the new content for further frames are autoregressively generated. Finally, in the <span class="dnerf">Streaming Refinement Stage</span> the generated long video (600, 1200 frames or more) is autoregressively enhanced by applying a high-resolution text-to-short-video model, equipped with our randomized blending approach.
          </p>
        </div>
      </div>
    </section>
  </div>
</section>

<!-- <script>
  function toggleDetails() {
    var content = document.getElementById("detailed-content");
    var triangle = document.getElementById("triangle");
    if (content.style.display === "none") {
      content.style.display = "block";
      triangle.innerHTML = "▲"; // Change triangle icon to point up
    } else {
      content.style.display = "none";
      triangle.innerHTML = "▼"; // Change triangle icon to point down
    }
  }
</script> -->

<!-- <section class="section" id="Method-Detailed">
  <div class="container is-max-desktop content">
    <h2 class="title">Method Detailed</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/t2v-v8.png" style="width:100%;height:80%;">
          <p>
            Method overview: In the Edge-Guided Image Super Resolution (EdgeSR) model, edge guidance is predominantly implemented in the later stages of the diffusion process to maximize clarity and effectiveness. Starting from a chosen midpoint, denoted as step S (0.5T, where T is the total number of diffusion steps), the model focuses on enhancing edge fidelity. At this stage, the latent image representation is transformed into a spatial image format using a VQ-GAN decoder. The resulting decoded image is then processed by the PiDiNet architecture, a network designed specifically for edge detection and enhancement. PiDiNet predicts an edge map, which is compared to the reference edge map derived from the initial low-resolution input. The discrepancy between the predicted and actual edge maps is quantified using a loss function, guiding the subsequent refinement of the image. This loss influences the diffusion process by integrating an anti-gradient adjustment directly into the latent representation, ensuring             the edges in the super-resolved image align more closely with those in the reference map. This adjustment, controlled by a scaling factor α, balances the strength of the edge guidance against the natural progression of image denoising. Through this method, EdgeSR effectively enhances the edge details in the super-resolved image, leveraging targeted modifications to improve image quality at critical stages of the reconstruction process.
          </p>
        </div>
      </div>
    </section>
  </div>
</section> -->


<section class="section " id="Results">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
    <section class="hero method">
    <div class="container is-max-desktop">
    <div class="hero-body">

    <h3 class="title">1200 FRAMES @ 2 MINUTES</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/1200/0002_0000_Explore_the_coral_gardens_of_the_sea__wi.mp4" controls></video></td>
        <td><video src="./static/videos/1200/0003_0000_Camera_moving_in_a_wide_bright_ice_cave,.mp4" controls></video></td>
        <td><video src="./static/videos/1200/0004_0000_Experience_the_dance_of_jellyfish__float.mp4" controls></video></td>
        <td><video src="./static/videos/1200/0005_0000_Wide_shot_of_battlefield,_stormtroopers_.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Explore the coral gardens of the sea..."</td>
        <td width=25% style="text-align:center;">"Camera moving in a wide bright ice cave."</td>
        <td width=25% style="text-align:center;">"Experience the dance of jellyfish..."</td>
        <td width=25% style="text-align:center;">"Wide shot of battlefield, stormtroopers running..."</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
    </table>

    <h3 class="title">600 FRAMES @ 1 MINUTE</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/600/0000_0000_Camera_following_a_pack_of_crows_flying_.mp4" controls></video></td>
        <td><video src="./static/videos/600/0000_0000_Marvel_at_the_diversity_of_bee_species_short.mp4" controls></video></td>
        <td><video src="./static/videos/600/0001_0000_Close_flyover_over_a_large_wheat_field_i.mp4" controls></video></td>
        <td><video src="./static/videos/600/0006_0000_Camera_moving_down_into_colorful_coral_r_short.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Camera following a pack of crows flying in the sky."</td>
        <td width=25% style="text-align:center;">"Marvel at the diversity of bee species..."</td>
        <td width=25% style="text-align:center;">"Close flyover over a large wheat field..."</td>
        <td width=25% style="text-align:center;">"Camera moving down into colorful coral reefs..."</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
    </table>

    <h3 class="title">240 FRAMES @ 24 SECONDS</h3>
    <table class="center">
      <tr><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/240/0023_0000_Fluids_mixing_and_changing_colors,_close.mp4"  controls></video></td>
        <td><video src="./static/videos/240/0009_0000_Santa_Claus_is_dancing.mp4" controls></video></td>
        <td><video src="./static/videos/240/0018_0000_Explosion,_burning,_smoke,_bomb,_nuclear.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Fluids mixing and changing colors."</td>
        <td width=25% style="text-align:center;">"Santa Claus is dancing."</td>
        <td width=25% style="text-align:center;">"Explosion."</td>
      </tr>
      <tr><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/240/0027_0000_Flying_through_nebulas_and_stars.mp4" controls></video></td>
        <td><video src="./static/videos/240/0035_0000_Camera_moving_closely_over_beautiful_ros.mp4" controls></video></td>
        <td><video src="./static/videos/240/0044_0000_Documenting_the_growth_cycle_of_vibrant_.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Flying through nebulas and stars."</td>
        <td width=25% style="text-align:center;">"Camera moving closely over beautiful roses blooming timelapse."</td>
        <td width=25% style="text-align:center;">"Documenting the growth cycle of vibrant lavender flowers..."</td>
      </tr>
      <tr><td></td><td></td><td></td></tr>
    </table>
    
    <h3 class="title">80 FRAMES @ 8 SECONDS</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/80/0005_0000_Ants,_beetles_and_centipede_nest.mp4" controls></video></td>
        <td><video src="./static/videos/80/0021_0000_Fishes_swimming_in_ocean_camera_moving,_.mp4" controls></video></td>
        <td><video src="./static/videos/80/0022_0000_A_squirrel_in_Antarctica,_on_a_pile_of_h.mp4" controls></video></td>
        <td><video src="./static/videos/80/0023_0000_Enter_the_fascinating_world_of_bees__exp.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Ants, beetles and centipede nest."</td>
        <td width=25% style="text-align:center;">"Fishes swimming in ocean camera moving."</td>
        <td width=25% style="text-align:center;">"A squirrel on a table full of big nuts."</td>
        <td width=25% style="text-align:center;">"Enter the fascinating world of bees..."</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><video src="./static/videos/80/0030_0000_A_hummingbird_flutters_among_colorful_fl.mp4" controls></video></td>
        <td><video src="./static/videos/80/0033_0000_Drone_fly_to_a_mansion_in_a_tropical_for.mp4" controls></video></td>
        <td><video src="./static/videos/80/0041_0000_Aerial__flying_above_a_breathtaking_lime.mp4" controls></video></td>
        <td><video src="./static/videos/80/0046_0000_Beneath_the_majestic_Northern_Lights_of_.mp4" controls></video></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A hummingbird flutters among colorful flowers..."</td>
        <td width=25% style="text-align:center;">"Drone fly to a mansion in a tropical forest."</td>
        <td width=25% style="text-align:center;">"Flying above a breathtaking limestone structure..."</td>
        <td width=25% style="text-align:center;">"Beneath the majestic Northern Lights of Iceland."</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
    </table>

  </div></div></section>
  </div>
</section>

<!-- 
<section class="section b-section" id='RelatedLinks'>
  <div class="container is-max-desktop content">
    <h2 class="title">Related Links</h2>
    <ul>
      <li><a href="https://modelscope.cn/models/iic/text-to-video-synthesis/summary">Modelscope</a></li>
      <li><a href="https://github.com/lllyasviel/ControlNet">Adding Conditional Control to Text-to-Image Diffusion Models (a.k.a ControlNet)</a></li>
      <li><a href="https://github.com/huggingface/diffusers">🤗 Diffusers</a></li>
      <li><a href="https://github.com/Doubiiu/DynamiCrafter">DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors</a></li>
    </ul>
  </div></section>
  </div>
</section>
 -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p> If you use our work in your research, please cite our publication: </p>
    <pre><code>@article{streamingt2v,
    title={StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text},
    author={Henschel, Roberto and Khachatryan, Levon and Hayrapetyan, Daniil and Poghosyan, Hayk and Tadevosyan, Vahram and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
    journal={arXiv preprint arXiv:2403.14773},
    year={2024}
  }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- FIX THE LINK -->
      <a class="icon-link" href="https://arxiv.org/abs/2403.14773">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled> -->
      <a class="icon-link" href="https://github.com/Picsart-AI-Research/StreamingT2V" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
